# 비츠 (Beats)

### 개요

비츠는 특정 목적에 집중해 데이터를 수집하는 데 특화된 경량 데이터 수집기입니다.

- **장점**:
    - 로그스태시(Logstash)는 범용적이지만 상대적으로 무거운 반면, 비츠는 특정 작업만 수행하도록 설계되어 경량화되어 있습니다.
    - 애플리케이션 성능에 영향을 주지 않으면서 실시간으로 데이터를 수집할 수 있습니다.
- **데이터 흐름**:
    - 비츠에서 수집한 데이터는 **엘라스틱서치(Elasticsearch)**로 바로 전송하거나, **로그스태시(Logstash)**를 통해 전송할 수 있습니다.
    - 로그스태시를 경유할 경우 데이터 가공 및 추가 처리가 가능하지만, 데이터 발생량이 적거나 복잡한 처리 필요가 없다면 로그스태시 없이도 사용 가능합니다.

---

### 비츠의 종류

1. **파일비트(Filebeat)**
    - 로그 파일을 실시간으로 읽어 전송합니다. 가장 많이 사용됩니다.
2. **하트비트(Heartbeat)**
    - 서비스 활성 상태를 모니터링합니다.
    - 크론 스케줄을 기반으로 핑(Ping) 또는 HTTP 서비스 체크 등을 수행합니다.
3. **메트릭비트(Metricbeat)**
    - CPU, 메모리, 데이터베이스, 프록시 등 운영체제 및 서비스의 통계 지표를 수집합니다.
4. **패킷비트(Packetbeat)**
    - 네트워크 데이터를 수집하여 트래픽, 응답 시간, 사용자 패턴 분석 등을 지원합니다.
5. **오딧비트(Auditbeat)**
    - 리눅스 **auditd**로 생성된 보안 로그를 수집합니다.
6. **저널비트(Journalbeat)**
    - 리눅스 **systemd** 서비스의 로그를 수집합니다.
7. **펑션비트(Functionbeat)**
    - 서버리스 환경에서 데이터를 수집하며, AWS Lambda 등에서 동작합니다.
8. **윈로그비트(Winlogbeat)**
    - 윈도우 이벤트 로그를 수집합니다.
9. **커스텀비트(Custom Beats)**
    - 오픈소스 커뮤니티에서 제공하는 비츠입니다. 예: 엔진엑스(Nginx) 비트, 카프카(Kafka) 비트 등.

---

### 파일비트(Filebeat) 아키텍처

파일비트는 고(Go) 언어로 작성되어 가볍게 실행되며, 간단한 필터링 작업도 가능합니다. 주요 구성요소는 다음과 같습니다:

1. **입력(Input)**
    - 설정 파일에서 입력 소스를 정의합니다.
    - 파일비트는 여러 입력을 지원합니다.
2. **하베스터(Harvester)**
    - 입력에서 지정된 파일을 한 줄씩 읽어 이벤트를 생성합니다.
    - 각 파일마다 하나의 하베스터가 생성됩니다.
3. **스풀러(Spooler)**
    - 하베스터가 수집한 이벤트를 엘라스틱서치, 로그스태시 등으로 전송합니다.

---

### 파일비트 설정 예제

```yaml
filebeat.inputs:
  - type: log
    enabled: true
    paths:
      - C:/elasticsearch-7.10.1/logs/*.log

output.elasticsearch:
  hosts: ["localhost:9200"]

setup.kibana:
  host: "localhost:5601"

```

### 입력(Input) 타입

- **log**: 기본 입력 타입으로, 파일시스템에서 로그 파일을 읽습니다.
- **container**: 도커 같은 컨테이너의 로그를 수집합니다.
- **s3**: AWS S3 버킷에 저장된 로그를 읽습니다.
- **kafka**: 카프카(Kafka)의 토픽 데이터를 읽어옵니다.

### 출력(Output) 타입

- **elasticsearch**: 데이터를 엘라스틱서치로 직접 전송합니다.
- **logstash**: 로그스태시로 데이터를 전송한 후, 추가 가공 및 처리합니다.
- **kafka**: 데이터를 카프카로 전송합니다.
- **console**: 수집한 데이터를 콘솔에 출력합니다.

---

### 추가 설정

1. **ignore_older**
    - 지정된 시간보다 오래된 파일은 무시합니다. 기본값은 `0`으로, 모든 파일을 읽습니다.
2. **include_lines** / **exclude_lines**
    - 정규표현식을 사용해 특정 로그 라인을 포함하거나 제외할 수 있습니다. 간단한 필터링 작업에 유용합니다.
3. **multiline**
    - 여러 줄로 구성된 로그를 하나의 이벤트로 처리합니다.
        - **pattern**: 정규표현식으로 패턴 정의
        - **negate**: `true` 설정 시, 패턴 조건을 반전
        - **match**:
            - `before`: 패턴에 일치하는 로그를 이전 라인에 붙임
            - `after`: 패턴에 일치하는 로그를 이후 라인에 붙임

---

### 모듈

모듈은 사전 정의된 설정 세트로, 복잡한 로그 수집을 쉽게 설정할 수 있습니다.

### 주요 모듈

- **aws**
- **googlecloud**
- **logstash**
- **cisco**: 네트워크 장비 이벤트 수집
- **cef**: CEF(Common Event Format) 이벤트 수집
- **elasticsearch**

### 모듈 활성화 예제

```bash
./filebeat.exe modules enable logstash

```

---

### 모니터링

비츠의 데이터 수집 상태 및 리소스 상태를 확인할 수 있습니다.

```yaml
output.elasticsearch:
  hosts: ["localhost:9200"]

setup.kibana:
  host: "localhost:5601"

monitoring.enabled: true
monitoring.cluster_uuid: PRODUCTIONS_ES_CLUSTER_UUID
monitoring.elasticsearch:
  hosts: ["localhost:9200"]

```

> 참고: 모니터링 클러스터와 파일비트의 엘라스틱서치 출력이 동일한 경우 cluster_uuid는 생략 가능합니다.
>